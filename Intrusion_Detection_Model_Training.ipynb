{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries and download dataset"
      ],
      "metadata": {
        "id": "wdMcvlRFxAPJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CdGGg85OKgHv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from itertools import combinations, product"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dhoogla/cicidscollection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClKL9uNgKnKW",
        "outputId": "6d977b05-e728-4637-b8ec-2cc3abdf341e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dhoogla/cicidscollection?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 825M/825M [00:30<00:00, 28.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dhoogla/cicidscollection/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files = os.listdir(path)\n",
        "\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oocHqo0cU4jw",
        "outputId": "0993c1b9-2a45-4346-a5df-287aed5bcf89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cic-collection.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/root/.cache/kagglehub/datasets/dhoogla/cicidscollection/versions/2/cic-collection.parquet\"\n",
        "print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3IwWSteverL",
        "outputId": "97e977c1-a8b0-4a47-8c52-da48fcbba3fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/dhoogla/cicidscollection/versions/2/cic-collection.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(path)"
      ],
      "metadata": {
        "id": "raUl85NHUluZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_QRVFGBwL4U",
        "outputId": "d4dfd84f-7edd-48ee-99d7-725a45d2e557"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
            "0              4                  2                       0   \n",
            "1              1                  2                       0   \n",
            "2              3                  2                       0   \n",
            "3              1                  2                       0   \n",
            "4            609                  7                       4   \n",
            "\n",
            "   Fwd Packets Length Total  Bwd Packets Length Total  Fwd Packet Length Max  \\\n",
            "0                      12.0                       0.0                    6.0   \n",
            "1                      12.0                       0.0                    6.0   \n",
            "2                      12.0                       0.0                    6.0   \n",
            "3                      12.0                       0.0                    6.0   \n",
            "4                     484.0                     414.0                  233.0   \n",
            "\n",
            "   Fwd Packet Length Mean  Fwd Packet Length Std  Bwd Packet Length Max  \\\n",
            "0                 6.00000               0.000000                    0.0   \n",
            "1                 6.00000               0.000000                    0.0   \n",
            "2                 6.00000               0.000000                    0.0   \n",
            "3                 6.00000               0.000000                    0.0   \n",
            "4                69.14286             111.967896                  207.0   \n",
            "\n",
            "   Bwd Packet Length Mean  ...  Active Mean  Active Std  Active Max  \\\n",
            "0                     0.0  ...          0.0         0.0         0.0   \n",
            "1                     0.0  ...          0.0         0.0         0.0   \n",
            "2                     0.0  ...          0.0         0.0         0.0   \n",
            "3                     0.0  ...          0.0         0.0         0.0   \n",
            "4                   103.5  ...          0.0         0.0         0.0   \n",
            "\n",
            "   Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  ClassLabel  \n",
            "0         0.0        0.0       0.0       0.0       0.0  Benign      Benign  \n",
            "1         0.0        0.0       0.0       0.0       0.0  Benign      Benign  \n",
            "2         0.0        0.0       0.0       0.0       0.0  Benign      Benign  \n",
            "3         0.0        0.0       0.0       0.0       0.0  Benign      Benign  \n",
            "4         0.0        0.0       0.0       0.0       0.0  Benign      Benign  \n",
            "\n",
            "[5 rows x 59 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning dataset"
      ],
      "metadata": {
        "id": "N-odwwgihCs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_df(df):\n",
        "    # Remove the space before each feature names\n",
        "    df.columns = df.columns.str.strip()\n",
        "    print('dataset shape', df.shape)\n",
        "\n",
        "    num = df._get_numeric_data()\n",
        "    num[num < 0] = 0\n",
        "\n",
        "    zero_variance_cols = []\n",
        "    for col in df.columns:\n",
        "        if len(df[col].unique()) == 1:\n",
        "            zero_variance_cols.append(col)\n",
        "    df.drop(zero_variance_cols, axis = 1, inplace = True)\n",
        "    print('zero variance columns', zero_variance_cols, 'dropped')\n",
        "    print('shape after removing zero variance columns:', df.shape)\n",
        "\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
        "    print(df.isna().any(axis = 1).sum(), 'rows dropped')\n",
        "    df.dropna(inplace = True)\n",
        "    print('shape after removing nan:', df.shape)\n",
        "\n",
        "    # Drop duplicate rows\n",
        "    df.drop_duplicates(inplace = True)\n",
        "    print('shape after dropping duplicates:', df.shape)\n",
        "\n",
        "    column_pairs = [(i, j) for i, j in combinations(df, 2) if df[i].equals(df[j])]\n",
        "    ide_cols = []\n",
        "    for column_pair in column_pairs:\n",
        "        ide_cols.append(column_pair[1])\n",
        "    df.drop(ide_cols, axis = 1, inplace = True)\n",
        "    print('columns which have identical values', column_pairs, 'dropped')\n",
        "    print('shape after removing identical value columns:', df.shape)\n",
        "    return df\n",
        "df = clean_df(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEbvynoOhI7z",
        "outputId": "883a0462-7ebc-4046-ed94-e1312fcdb45a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape (9167581, 59)\n",
            "zero variance columns [] dropped\n",
            "shape after removing zero variance columns: (9167581, 59)\n",
            "0 rows dropped\n",
            "shape after removing nan: (9167581, 59)\n",
            "shape after dropping duplicates: (9162310, 59)\n",
            "columns which have identical values [('Total Fwd Packets', 'Subflow Fwd Packets'), ('Total Backward Packets', 'Subflow Bwd Packets'), ('Fwd Packet Length Mean', 'Avg Fwd Segment Size'), ('Bwd Packet Length Mean', 'Avg Bwd Segment Size')] dropped\n",
            "shape after removing identical value columns: (9162310, 55)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qy-g5NWSeguK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore and preprocess data"
      ],
      "metadata": {
        "id": "pxc7QIGLxm4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11riKAZx87yw",
        "outputId": "1d9cb327-3b42-4b0f-87a8-6951c18a675c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
            "       'Fwd Packets Length Total', 'Bwd Packets Length Total',\n",
            "       'Fwd Packet Length Max', 'Fwd Packet Length Mean',\n",
            "       'Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
            "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
            "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
            "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
            "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
            "       'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags',\n",
            "       'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s',\n",
            "       'Bwd Packets/s', 'Packet Length Max', 'Packet Length Mean',\n",
            "       'Packet Length Std', 'Packet Length Variance', 'SYN Flag Count',\n",
            "       'URG Flag Count', 'Avg Packet Size', 'Subflow Fwd Bytes',\n",
            "       'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes',\n",
            "       'Fwd Act Data Packets', 'Fwd Seg Size Min', 'Active Mean', 'Active Std',\n",
            "       'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max',\n",
            "       'Idle Min', 'Label', 'ClassLabel'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hq4VUYLczrgb",
        "outputId": "75066179-01d5-4f10-a041-7a49a864adde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Label\n",
              "Benign                  7185877\n",
              "DDoS-LOIC-HTTP           575364\n",
              "DoS-Hulk                 318740\n",
              "DDoS-HOIC                198861\n",
              "Botnet                   145968\n",
              "DDoS                     128062\n",
              "DDoS-NTP                 121102\n",
              "Bruteforce-SSH            97260\n",
              "DDoS-TFTP                 96488\n",
              "Infiltration              94857\n",
              "DoS-Goldeneye             52324\n",
              "DDoS-Syn                  47757\n",
              "DDoS-UDP                  28697\n",
              "DoS-Slowloris             15243\n",
              "DDoS-MSSQL                10301\n",
              "DDoS-UDPLag                8450\n",
              "Bruteforce-FTP             5984\n",
              "DoS-Slowhttptest           5271\n",
              "DDoS-Ddossim               5115\n",
              "DDoS-DNS                   3271\n",
              "DoS-Slowread               2786\n",
              "Portscan                   2254\n",
              "DDoS-LDAP                  2038\n",
              "Webattack-bruteforce       2020\n",
              "DDoS-Slowloris             1858\n",
              "DDoS-SNMP                  1811\n",
              "DoS-Slowheaders            1649\n",
              "Webattack-XSS               876\n",
              "DoS-Rudy                    699\n",
              "DoS-Slowbody                621\n",
              "DDoS-NetBIOS                596\n",
              "Webattack-SQLi               99\n",
              "DoS-Heartbleed               11\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>7185877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-LOIC-HTTP</th>\n",
              "      <td>575364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Hulk</th>\n",
              "      <td>318740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-HOIC</th>\n",
              "      <td>198861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Botnet</th>\n",
              "      <td>145968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS</th>\n",
              "      <td>128062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-NTP</th>\n",
              "      <td>121102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bruteforce-SSH</th>\n",
              "      <td>97260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-TFTP</th>\n",
              "      <td>96488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Infiltration</th>\n",
              "      <td>94857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Goldeneye</th>\n",
              "      <td>52324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-Syn</th>\n",
              "      <td>47757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-UDP</th>\n",
              "      <td>28697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slowloris</th>\n",
              "      <td>15243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-MSSQL</th>\n",
              "      <td>10301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-UDPLag</th>\n",
              "      <td>8450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bruteforce-FTP</th>\n",
              "      <td>5984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slowhttptest</th>\n",
              "      <td>5271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-Ddossim</th>\n",
              "      <td>5115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-DNS</th>\n",
              "      <td>3271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slowread</th>\n",
              "      <td>2786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Portscan</th>\n",
              "      <td>2254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-LDAP</th>\n",
              "      <td>2038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Webattack-bruteforce</th>\n",
              "      <td>2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-Slowloris</th>\n",
              "      <td>1858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-SNMP</th>\n",
              "      <td>1811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slowheaders</th>\n",
              "      <td>1649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Webattack-XSS</th>\n",
              "      <td>876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Rudy</th>\n",
              "      <td>699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Slowbody</th>\n",
              "      <td>621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS-NetBIOS</th>\n",
              "      <td>596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Webattack-SQLi</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS-Heartbleed</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels from the original DataFrame\n",
        "features = df.drop(['Label', 'ClassLabel'], axis=1)\n",
        "labels = df['Label']\n",
        "\n",
        "# Split data into training and testing sets using raw data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split the raw test set into local test and demo sets\n",
        "X_test, demo_test, y_test, demo_label = train_test_split(\n",
        "    X_test, y_test, test_size=0.001, random_state=42)\n",
        "\n",
        "# Download demo data\n",
        "demo_dataframe = pd.DataFrame(demo_test)\n",
        "\n",
        "# Calculate the midpoint of the demo dataframe\n",
        "mid_index = len(demo_dataframe) // 2\n",
        "\n",
        "# Split the dataframe into two halves using iloc\n",
        "demo_dataframe_1 = demo_dataframe.iloc[:mid_index]\n",
        "demo_dataframe_2 = demo_dataframe.iloc[mid_index:]\n",
        "\n",
        "# Save each half to separate CSV files\n",
        "demo_dataframe_1.to_csv(\"demo_data_1.csv\", index=False)\n",
        "demo_dataframe_2.to_csv(\"demo_data_2.csv\", index=False)"
      ],
      "metadata": {
        "id": "JUirgIt3ljlV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale and normalize the training and local test data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# One-hot encode the labels for training and local test data\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test = encoder.fit_transform(y_test.values.reshape(-1, 1))\n",
        "\n",
        "# Get the order of label encodings to map out later\n",
        "print(encoder.get_feature_names_out())"
      ],
      "metadata": {
        "id": "sCgW1E0rO-11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44e5842-f34f-4476-a8a7-06cff4a8a789"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['x0_Benign' 'x0_Botnet' 'x0_Bruteforce-FTP' 'x0_Bruteforce-SSH' 'x0_DDoS'\n",
            " 'x0_DDoS-DNS' 'x0_DDoS-Ddossim' 'x0_DDoS-HOIC' 'x0_DDoS-LDAP'\n",
            " 'x0_DDoS-LOIC-HTTP' 'x0_DDoS-MSSQL' 'x0_DDoS-NTP' 'x0_DDoS-NetBIOS'\n",
            " 'x0_DDoS-SNMP' 'x0_DDoS-Slowloris' 'x0_DDoS-Syn' 'x0_DDoS-TFTP'\n",
            " 'x0_DDoS-UDP' 'x0_DDoS-UDPLag' 'x0_DoS-Goldeneye' 'x0_DoS-Heartbleed'\n",
            " 'x0_DoS-Hulk' 'x0_DoS-Rudy' 'x0_DoS-Slowbody' 'x0_DoS-Slowheaders'\n",
            " 'x0_DoS-Slowhttptest' 'x0_DoS-Slowloris' 'x0_DoS-Slowread'\n",
            " 'x0_Infiltration' 'x0_Portscan' 'x0_Webattack-SQLi' 'x0_Webattack-XSS'\n",
            " 'x0_Webattack-bruteforce']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(y_train), len(X_test), len(y_test), len(features), len(labels)"
      ],
      "metadata": {
        "id": "21Lfh1j241dv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91e6b2c-09d9-412c-c8a3-d84090b83399"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7329848, 7329848, 1830629, 1830629, 9162310, 9162310)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the LSTM model and make predictions"
      ],
      "metadata": {
        "id": "j8eFQCB_JdNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "R7LUyiww4XBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "Ni_66ZeMNfAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# Define LSTM Model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc(x[:, -1, :])  # Using the last time-step output\n",
        "        return x\n",
        "\n",
        "# Reshape tensors on CPU\n",
        "X_train_tensor = X_train_tensor.reshape((X_train_tensor.shape[0], 1, X_train_tensor.shape[1]))\n",
        "X_test_tensor = X_test_tensor.reshape((X_test_tensor.shape[0], 1, X_test_tensor.shape[1]))\n",
        "\n",
        "# Create DataLoader for CPU tensors\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
        "\n",
        "# Initialize the model and move it to GPU\n",
        "input_size = X_train_tensor.shape[2]\n",
        "hidden_size = 128\n",
        "output_size = y_train_tensor.shape[1]\n",
        "model = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "# Use BCEWithLogitsLoss that is safe for autocasting\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scaler = torch.amp.GradScaler()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "apLbEZoq4SCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Hidden size: {hidden_size}, input size: {input_size}, output size: {output_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg2tJ31sb-w5",
        "outputId": "0f18285e-330a-47c1-c134-b3259a8e8cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden size: 128, input size: 53, output size: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with mixed precision and DataLoader batch transfer to GPU\n",
        "epochs = 6\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        # Move batch data to GPU\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        batch_y = batch_y.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.amp.autocast(device_type=device.type):\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss / len(train_loader):.4f}')"
      ],
      "metadata": {
        "id": "gwbgS5Qdb4S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader for test dataset\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, pin_memory=True)\n",
        "\n",
        "model.eval()\n",
        "all_logits = []\n",
        "with torch.no_grad():\n",
        "    for batch_x, _ in test_loader:\n",
        "        batch_x = batch_x.to(device, non_blocking=True)\n",
        "        logits = model(batch_x)\n",
        "        all_logits.append(logits.cpu())\n",
        "# Concatenate results from all batches\n",
        "all_logits = torch.cat(all_logits, dim=0)\n",
        "# Convert logits to probabilities and then binary predictions\n",
        "probs = torch.sigmoid(all_logits)\n",
        "y_pred = (probs > 0.5).float()\n",
        "accuracy = accuracy_score(y_test_tensor.numpy(), y_pred.numpy())\n",
        "print(f'Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqTfBYo9zbi3",
        "outputId": "4da734dc-b2a2-46ee-8193-2a4446dd2854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "4XHT5M-yRwDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2TOZ2Bew9UDj",
        "outputId": "69a1d275-e2a8-44f8-c10d-7fe871b92f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b331ec58-0121-49d5-af4b-77704fda4b03\", \"model.pth\", 922688)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}